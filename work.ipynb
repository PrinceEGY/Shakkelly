{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from utils import constants\n",
    "from utils.preprocessor import Preprocessor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_train_df, ca_val_df, ca_test_df = pd.read_csv('./dataset/Tashkeela-clean-V2.0/CA/CA_train.csv'), pd.read_csv('./dataset/Tashkeela-clean-V2.0/CA/CA_val.csv'), pd.read_csv('./dataset/Tashkeela-clean-V2.0/CA/CA_test.csv')\n",
    "msa_train_df, msa_val_df, msa_test_df = pd.read_csv('./dataset/Tashkeela-clean-V2.0/MSA/MSA_train.csv'), pd.read_csv('./dataset/Tashkeela-clean-V2.0/MSA/MSA_val.csv'), pd.read_csv('./dataset/Tashkeela-clean-V2.0/MSA/MSA_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>chars</th>\n",
       "      <th>chars_no_diac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>وَفِي بَعْضِ النُّسَخِ بِالْإِضَافَةِ فَصَالَح...</td>\n",
       "      <td>60</td>\n",
       "      <td>479</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>غَيْرِ وَلِيِّ مَنْ ذُكِرَ دَفْعُ سِنٍّ أَعْلَ...</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَمِمَّنْ حَكَى أَنْ يُعَلِّمُ بِمَعْنَى أَعْل...</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>وَيَخْرُجُ بِتَعْبِيرِ الْمَالِ الْمَنْفَعَةُ ...</td>\n",
       "      <td>15</td>\n",
       "      <td>156</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>زَوْجَانِ كَافِرَانِ أَسْلَمَتْ الْمَرْأَةُ وَ...</td>\n",
       "      <td>28</td>\n",
       "      <td>248</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365073</th>\n",
       "      <td>إنْ ظَهَرَتْ قَرِينَةٌ تُقَوِّي صِدْقَ السَّيّ...</td>\n",
       "      <td>25</td>\n",
       "      <td>202</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365074</th>\n",
       "      <td>لِأَنَّهُ يُعَارِضُ ظَاهِرَ الزَّوْجِ بِالْيَد...</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365075</th>\n",
       "      <td>وَإِلَّا لَمْ يَقَعْ فَرْضًا وَلَا نَفْلًا قَا...</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365076</th>\n",
       "      <td>رَوَاهُ مُسْلِمٌ فِى الصَّحِيحِ عَنْ عَمْرٍو ا...</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365077</th>\n",
       "      <td>لِأَنَّهُمْ لَمَّا نَزَّلُوا الْبَيْضَ مَنْزِل...</td>\n",
       "      <td>21</td>\n",
       "      <td>194</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2365078 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  words  chars  \\\n",
       "0        وَفِي بَعْضِ النُّسَخِ بِالْإِضَافَةِ فَصَالَح...     60    479   \n",
       "1        غَيْرِ وَلِيِّ مَنْ ذُكِرَ دَفْعُ سِنٍّ أَعْلَ...     14    100   \n",
       "2        وَمِمَّنْ حَكَى أَنْ يُعَلِّمُ بِمَعْنَى أَعْل...      9     90   \n",
       "3        وَيَخْرُجُ بِتَعْبِيرِ الْمَالِ الْمَنْفَعَةُ ...     15    156   \n",
       "4        زَوْجَانِ كَافِرَانِ أَسْلَمَتْ الْمَرْأَةُ وَ...     28    248   \n",
       "...                                                    ...    ...    ...   \n",
       "2365073  إنْ ظَهَرَتْ قَرِينَةٌ تُقَوِّي صِدْقَ السَّيّ...     25    202   \n",
       "2365074  لِأَنَّهُ يُعَارِضُ ظَاهِرَ الزَّوْجِ بِالْيَد...      8     70   \n",
       "2365075  وَإِلَّا لَمْ يَقَعْ فَرْضًا وَلَا نَفْلًا قَا...      9     73   \n",
       "2365076  رَوَاهُ مُسْلِمٌ فِى الصَّحِيحِ عَنْ عَمْرٍو ا...      9     70   \n",
       "2365077  لِأَنَّهُمْ لَمَّا نَزَّلُوا الْبَيْضَ مَنْزِل...     21    194   \n",
       "\n",
       "         chars_no_diac  \n",
       "0                  285  \n",
       "1                   60  \n",
       "2                   51  \n",
       "3                   91  \n",
       "4                  145  \n",
       "...                ...  \n",
       "2365073            117  \n",
       "2365074             41  \n",
       "2365075             43  \n",
       "2365076             43  \n",
       "2365077            113  \n",
       "\n",
       "[2365078 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_train_raw = tf.data.Dataset.from_tensor_slices(ca_train_df['text'])\n",
    "ca_val_raw = tf.data.Dataset.from_tensor_slices(ca_val_df['text'])\n",
    "ca_test_raw = tf.data.Dataset.from_tensor_slices(ca_test_df['text'])\n",
    "\n",
    "msa_train_raw = tf.data.Dataset.from_tensor_slices(msa_train_df['text'])\n",
    "msa_val_raw = tf.data.Dataset.from_tensor_slices(msa_val_df['text'])\n",
    "msa_test_raw = tf.data.Dataset.from_tensor_slices(msa_test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_strip_tashkeel(inputs):\n",
    "    @tf.py_function(Tout=(tf.string, tf.string))\n",
    "    def strip_tashkeel(inputs):\n",
    "        text = inputs.numpy().decode('utf-8')\n",
    "        text, tashkeel = Preprocessor.strip_tashkeel(text)\n",
    "        text = tf.convert_to_tensor(text, dtype=tf.string)\n",
    "        tashkeel = tf.convert_to_tensor(tashkeel, dtype=tf.string)\n",
    "        return text, tashkeel\n",
    "    text, tashkeel = strip_tashkeel(inputs)\n",
    "    text.set_shape((None, ))\n",
    "    tashkeel.set_shape((None, ))\n",
    "    return text, tashkeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_tok = keras.layers.TextVectorization(\n",
    "    ragged=True,\n",
    "    standardize=lambda x:tf.concat([[\"s\"], x, [\"e\"]], axis=-1),\n",
    "    split=None,\n",
    "    )\n",
    "diac_tok = keras.layers.TextVectorization(\n",
    "    standardize=lambda x:tf.concat([[\" \"], x, [\" \"]], axis=-1),\n",
    "    ragged=True,\n",
    "    split=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_tok.adapt(msa_train_raw.take(200).map(tf_strip_tashkeel).map(lambda x, y: x))\n",
    "diac_tok.adapt(msa_train_raw.take(200).map(tf_strip_tashkeel).map(lambda x, y: y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_word_to_idx = keras.layers.StringLookup(vocabulary=letters_tok.get_vocabulary(), mask_token='')\n",
    "lt_idx_to_word = keras.layers.StringLookup(vocabulary=letters_tok.get_vocabulary(), mask_token='', invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diac_word_to_idx = keras.layers.StringLookup(vocabulary=diac_tok.get_vocabulary(), mask_token='')\n",
    "diac_idx_to_word = keras.layers.StringLookup(vocabulary=diac_tok.get_vocabulary(), mask_token='', invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ds(ds, batch_size=32, shuffle_buffer=1000):\n",
    "    ds = (\n",
    "        ds.map(tf_strip_tashkeel, tf.data.AUTOTUNE)\n",
    "        .map(lambda x, y: (letters_tok(x), diac_tok(y)), tf.data.AUTOTUNE)\n",
    "        .shuffle(shuffle_buffer)\n",
    "        .padded_batch(batch_size)\n",
    "        )\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_train = process_ds(msa_train_raw)\n",
    "msa_val = process_ds(msa_val_raw)\n",
    "msa_test = process_ds(msa_test_raw)\n",
    "\n",
    "ca_train = process_ds(ca_train_raw)\n",
    "ca_val = process_ds(ca_val_raw)\n",
    "ca_test = process_ds(ca_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(msa_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentences(sentences):\n",
    "    # work on batch size\n",
    "    return [[char.decode('utf-8') for char in l.numpy()] for l in lt_idx_to_word(sentences)]\n",
    "\n",
    "def decode_diacritics(diacritics):\n",
    "    # work on batch size\n",
    "    return [[char.decode('utf-8') for char in d.numpy()] for d in diac_idx_to_word(diacritics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_sen = decode_sentences(sample[0])\n",
    "dec_diac = decode_diacritics(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('غير أن الإسلام زحف على بلادهم من زمن بعيد فأسلمت أطرافها من كل اتجاه', 123)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = tf.strings.reduce_join(dec_sen[0], axis=-1).numpy()[1:-1]\n",
    "sen.decode('utf-8'), len(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'غَيْرَ أَنَّ الْإِسْلَامَ زَحَفَ عَلَى بِلَادِهِمْ مِنْ زَمَنٍ بَعِيدٍ فَأَسْلَمَتْ أَطْرَافُهَا مِنْ كُلِّ اتِّجَاهٍ'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eof_idx = dec_sen[0].index('e')\n",
    "Preprocessor.combine_tashkeel(dec_sen[0][1:eof_idx], dec_diac[0][1:eof_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 293), dtype=int64, numpy=\n",
       " array([[19,  8, 23, ...,  0,  0,  0],\n",
       "        [19,  8, 12, ...,  0,  0,  0],\n",
       "        [19,  8, 12, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [19, 33,  6, ...,  0,  0,  0],\n",
       "        [19,  8, 24, ...,  0,  0,  0],\n",
       "        [19,  8, 28, ...,  0,  0,  0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(32, 293), dtype=int64, numpy=\n",
       " array([[2, 3, 3, ..., 0, 0, 0],\n",
       "        [2, 3, 4, ..., 0, 0, 0],\n",
       "        [2, 3, 6, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 6, 7, ..., 0, 0, 0],\n",
       "        [2, 3, 4, ..., 0, 0, 0],\n",
       "        [2, 3, 3, ..., 0, 0, 0]], dtype=int64)>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ca_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = keras.layers.Input(shape=(None,), dtype=tf.int64)\n",
    "    x = keras.layers.Embedding(len(letters_tok.get_vocabulary())+1, 128, mask_zero=True)(inputs)\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.4))(x)\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.4))(x)\n",
    "    x = keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = keras.layers.Dense(len(diac_tok.get_vocabulary())+1, activation='relu')(x)\n",
    "    model = keras.models.Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(labels, preds):\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=None\n",
    "    )\n",
    "    loss = loss_fn(labels, preds)\n",
    "\n",
    "    mask = labels != 0\n",
    "    mask = tf.cast(mask, loss.dtype)\n",
    "\n",
    "    loss = loss * mask\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(0.001), loss=masked_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ bidirectional_14… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ bidirectional_15… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m5,376\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m263,168\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m394,240\u001b[0m │ bidirectional_14… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m131,584\u001b[0m │ bidirectional_15… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)  │      \u001b[38;5;34m8,721\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">803,089</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m803,089\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">803,089</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m803,089\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\PrinceEGY\\AppData\\Local\\Temp\\ipykernel_28220\\2738802094.py\", line 3, in custom_met  *\n        labels = labels.numpy()\n\n    AttributeError: 'SymbolicTensor' object has no attribute 'numpy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsa_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsa_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PrinceEGY\\anaconda3\\envs\\Shakkel\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\PRINCE~1\\AppData\\Local\\Temp\\__autograph_generated_file0y8gu_zf.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__custom_met\u001b[1;34m(labels, preds)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m labels \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m preds \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(preds)\u001b[38;5;241m.\u001b[39mnumpy, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\PrinceEGY\\AppData\\Local\\Temp\\ipykernel_28220\\2738802094.py\", line 3, in custom_met  *\n        labels = labels.numpy()\n\n    AttributeError: 'SymbolicTensor' object has no attribute 'numpy'\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    msa_train.repeat(),\n",
    "    steps_per_epoch=200,\n",
    "    validation_data=msa_val,\n",
    "    epochs=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 0.3005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29762324690818787"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(msa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp = next(iter(msa_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 143), dtype=int64, numpy=\n",
       " array([[19, 22,  5, ...,  0,  0,  0],\n",
       "        [19,  8,  6, ...,  0,  0,  0],\n",
       "        [19, 10, 11, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [19,  8,  3, ...,  0,  0,  0],\n",
       "        [19, 11,  4, ...,  0,  0,  0],\n",
       "        [19,  8, 15, ...,  0,  0,  0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(32, 143), dtype=int64, numpy=\n",
       " array([[2, 3, 5, ..., 0, 0, 0],\n",
       "        [2, 3, 4, ..., 0, 0, 0],\n",
       "        [2, 6, 3, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 3, 2, ..., 0, 0, 0],\n",
       "        [2, 3, 3, ..., 0, 0, 0],\n",
       "        [2, 3, 3, ..., 0, 0, 0]], dtype=int64)>)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(smp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentences = decode_sentences(smp[0])\n",
    "decoded_diacritics = decode_diacritics(smp[1])\n",
    "decoded_diacritics_p = decode_diacritics(tf.argmax(res, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('وإن غلب جوهر ظلمته على جوهر نوره وظهرت جسمانيته على روحانيته فقد فضل على الشيطان',\n",
       " 146)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = tf.strings.reduce_join(decoded_sentences[idx], axis=-1).numpy()[1:-1]\n",
    "sen.decode('utf-8'), len(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وَإِنْ غَلَبَ جَوْهَرُ ظُلْمَتِهِ عَلَى جَوْهَرِ نُورِهِ وَظَهَرَتْ جِسْمَانِيَّتُهُ عَلَى رُوحَانِيَّتِهِ فَقَدْ فَضَلَ عَلَى الشَّيْطَانِ'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Preprocessor.combine_tashkeel(decoded_sentences[idx][1:decoded_sentences[idx].index('e')], decoded_diacritics[idx][1:decoded_sentences[idx].index('e')])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وَإِنْ غَلَبَ جَوهَرَ ظَلَمَتَهُ عَلَى جُوهَرِ نُوْرِهِ وَظَهَرَتْ جُسْمَانِيَّتَهُ عَلَى رُوحَانِيَّتِهِ فَقَدْ فَضَلَ عَلَى الشَّيْطَانِ'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Preprocessor.combine_tashkeel(decoded_sentences[idx][1:decoded_sentences[idx].index('e')], decoded_diacritics_p[idx][1:decoded_sentences[idx].index('e')])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diacritization_evaluation import wer, der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, ds):\n",
    "    # Works on batched datasets only\n",
    "    def combine_per_sen(sen, diac):\n",
    "        eof_idx = sen.index('e')\n",
    "        res = Preprocessor.combine_tashkeel(sen[1:eof_idx], diac[1:eof_idx])\n",
    "        return res\n",
    "    \n",
    "    ds_len = (len(ds) * ds._batch_size.numpy())\n",
    "    res = {\"wer\":0, \"wer*\":0, \"der\":0, \"der*\":0}\n",
    "    for sen, diac in tqdm(ds):\n",
    "        preds = model(sen)\n",
    "        decoded_sentences = decode_sentences(sen)\n",
    "        decoded_diacritics_t = decode_diacritics(diac)\n",
    "        decoded_diacritics_p = decode_diacritics(tf.argmax(preds, -1))\n",
    "        idx = 0\n",
    "        while idx < len(decoded_sentences):\n",
    "            true_diac = combine_per_sen(decoded_sentences[idx], decoded_diacritics_t[idx])\n",
    "            pred_diac = combine_per_sen(decoded_sentences[idx], decoded_diacritics_p[idx])\n",
    "            res[\"wer\"] += wer.calculate_wer(true_diac, pred_diac) / ds_len\n",
    "            res[\"wer*\"] += wer.calculate_wer(true_diac, pred_diac, case_ending=False) / ds_len\n",
    "            res[\"der\"] += der.calculate_der(true_diac, pred_diac) / ds_len\n",
    "            res[\"der*\"] += der.calculate_der(true_diac, pred_diac, case_ending=False) / ds_len\n",
    "            idx+=1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:10<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "res=calculate_metrics(model, msa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 37.763051861702166,\n",
       " 'wer*': 25.14950797872337,\n",
       " 'der': 10.22831117021276,\n",
       " 'der*': 8.052779255319125}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Shakkel",
   "language": "python",
   "name": "shakkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
